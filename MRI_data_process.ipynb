{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import glob\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_slice_list(data_shape):\n",
    "    x_max, y_max, z_max = data_shape\n",
    "    x_curr = randint((x_max/2)-(x_max/4), (x_max/2)+(x_max/4))\n",
    "    y_curr = randint((y_max/2)-(y_max/4), (y_max/2)+(y_max/4))\n",
    "    z_curr = randint((z_max/2)-(z_max/4), (z_max/2)+(z_max/4))\n",
    "    return x_curr, y_curr, z_curr\n",
    "\n",
    "\n",
    "\n",
    "def show_mri_slices_random(mri_data, explicit_pos=None):\n",
    "    \"\"\" Function to display random image slices \"\"\"\n",
    "    '''Provision to give exact slice numbers'''\n",
    "    '''Random numbers biased towards middle'''\n",
    "    \n",
    "    print('Data Shape = ',mri_data.shape)\n",
    "    if explicit_pos==None:\n",
    "        x_curr, y_curr, z_curr = get_rand_slice_list(mri_data.shape)\n",
    "    else:\n",
    "        x_curr, y_curr, z_curr = explicit_pos\n",
    "    print('Data Positions = ',x_curr, y_curr, z_curr)\n",
    "    slice_0 = mri_data[x_curr, :, :]\n",
    "    slice_1 = mri_data[:, y_curr, :]\n",
    "    slice_2 = mri_data[:, :, z_curr]\n",
    "    print('Slice 1: value: ',x_curr)\n",
    "    plt.imshow(slice_0.T, cmap='gray', origin=0)\n",
    "    plt.show()\n",
    "    print('Slice 2: value: ',y_curr)\n",
    "    plt.imshow(slice_1.T, cmap='gray', aspect=0.5, origin=0)\n",
    "    plt.show()\n",
    "    print('Slice 3: value: ',z_curr)\n",
    "    plt.imshow(slice_2.T, cmap='gray', aspect=0.5, origin=0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def BrainMasker(brain_data,skull_data, brain_obj=None,isSave=False):\n",
    "    maskedObj = np.ma.masked_array(brain_data,(skull_data+1)%2, fill_value=0)\n",
    "    h = maskedObj.filled()\n",
    "    if isSave:\n",
    "        if brain_obj==None:\n",
    "            print('No affine transform available. provide brain object')\n",
    "        else:\n",
    "            new_image = nib.Nifti1Image(h, brain_obj.affine)\n",
    "            nib.save(new_image, \"output.nii.gz\")\n",
    "    return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'F:\\\\7thsemProjects\\\\MRIAnalysis\\\\3dmrMS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MS_dataset_paths(MS_dataset_path):\n",
    "    actual_data={}\n",
    "    list_of_set_of_datasets =glob.glob(MS_dataset_path+'/*/')\n",
    "    whole_list_of_datasets=[]\n",
    "    for set_of_datasets in list_of_set_of_datasets:\n",
    "        list_of_datasets = glob.glob(set_of_datasets+'/*/')\n",
    "        whole_list_of_datasets.extend(list_of_datasets)\n",
    "    #print((whole_list_of_datasets))\n",
    "    for curr_data_path in whole_list_of_datasets:\n",
    "        curr_dataset={}\n",
    "        curr_dataset['brainmask'] = glob.glob(curr_data_path+'/*brainmask.nii.gz')[-1]\n",
    "        curr_dataset['segmentation'] = glob.glob(curr_data_path+'/*consensus_gt.nii.gz')[-1]\n",
    "        curr_dataset['t1w'] = glob.glob(curr_data_path+'/*T1W.nii.gz')[-1]\n",
    "        curr_dataset['t1w_enhance'] = glob.glob(curr_data_path+'/*T1WKS.nii.gz')[-1]\n",
    "        curr_dataset['t2w'] = glob.glob(curr_data_path+'/*T2W.nii.gz')[-1]\n",
    "        curr_dataset['flair'] = glob.glob(curr_data_path+'/*FLAIR.nii.gz')[-1]\n",
    "        for name,val in curr_dataset.items():\n",
    "            if val==[]:\n",
    "                print('Error at',name,': ',curr_data_path)\n",
    "                return\n",
    "        dataset_name_parts = curr_data_path.split(os.sep)\n",
    "        dataset_name_parts.pop()\n",
    "        dataset_name = dataset_name_parts.pop()\n",
    "        \n",
    "        actual_data[dataset_name]=curr_dataset\n",
    "        \n",
    "    return actual_data \n",
    "\n",
    "def load_dataset_details(MS_dataset_path):\n",
    "    file=MS_dataset_path + '\\patient26-30\\patient_info.csv'\n",
    "    dict_list = []\n",
    "    with open(file) as fh:\n",
    "        rd = csv.DictReader(fh, delimiter=',') \n",
    "        for row in rd:\n",
    "            dict_list.append(dict(row))\n",
    "    return dict_list\n",
    "\n",
    "def list_dataset(datasets_path_list):\n",
    "    for i, val in datasets_path_list.items():\n",
    "        print(i,val)\n",
    "        \n",
    "        \n",
    "def show_all_data_patient(patient_datapath_dict):\n",
    "    t1w_obj = nib.load(patient_datapath_dict['t1w'])\n",
    "    t2w_obj = nib.load(patient_datapath_dict['t2w'])\n",
    "    flair_obj = nib.load(patient_datapath_dict['flair'])\n",
    "    skull_obj = nib.load(patient_datapath_dict['brainmask'])\n",
    "    concensus_obj = nib.load(patient_datapath_dict['segmentation'])\n",
    "    \n",
    "    t1w_data = t1w_obj.get_fdata()\n",
    "    t2w_data = t2w_obj.get_fdata()\n",
    "    flair_data = flair_obj.get_fdata()\n",
    "    concensus_data = concensus_obj.get_fdata()\n",
    "    skull_data = skull_obj.get_fdata()\n",
    "    \n",
    "    x,y,z = get_rand_slice_list(t1w_data.shape)\n",
    "    \n",
    "    print('t1w')\n",
    "    show_mri_slices_random(t1w_data,(x,y,z))\n",
    "    print('t2w')\n",
    "    show_mri_slices_random(t2w_data,(x,y,z))\n",
    "    print('flair')\n",
    "    show_mri_slices_random(flair_data,(x,y,z))\n",
    "    print('concensus')\n",
    "    show_mri_slices_random(concensus_data,(x,y,z))\n",
    "    print('skull data')\n",
    "    show_mri_slices_random(skull_data,(x,y,z))\n",
    "    \n",
    "    print('t1w masked')\n",
    "    t1w_masked=BrainMasker(t1w_data,skull_data)\n",
    "    show_mri_slices_random(t1w_masked,(x,y,z))\n",
    "    print('t2w masked')\n",
    "    t2w_masked=BrainMasker(t2w_data,skull_data)\n",
    "    show_mri_slices_random(t2w_masked,(x,y,z))\n",
    "    print('flair masked')\n",
    "    flair_masked=BrainMasker(flair_data,skull_data)\n",
    "    show_mri_slices_random(flair_masked,(x,y,z))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process PipeLine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dataset Loading\n",
    "2. Dataset Viewing\n",
    "3. Image Processing\n",
    "    a. Skull Stripping\n",
    "    b. Intensity Normalization - https://github.com/loli/medpy/blob/master/medpy/filter/IntensityRangeStandardization.py\n",
    "    c. Size Standardization\n",
    "4. Goal #1\n",
    "    Getting segmented images using flair mri scans only\n",
    "    \n",
    "    \n",
    "5. Scoring in Segmentation\n",
    "    Dice Scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
